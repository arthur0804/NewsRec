{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script generate the topic modeling for the corpus \n",
    "# It find the topic collections of documents and documents' prob. distribution over topics\n",
    "# Run it on the longleaf server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora,models\n",
    "import gensim\n",
    "import nltk\n",
    "import re\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(folder_path):\n",
    "    \n",
    "    '''\n",
    "    Args: folder path\n",
    "    Returns: id list and corresponding content list \n",
    "    '''\n",
    "    \n",
    "    news_id_list = []\n",
    "    news_content_list = []\n",
    "    \n",
    "    for file in os.listdir(folder_path):\n",
    "        if file[-5:] == \".json\":\n",
    "            with open(folder_path + file, 'r', encoding=\"utf-8\") as f:\n",
    "                news = json.load(f)\n",
    "                news_content = news[\"content\"]\n",
    "                news_content_list.append(news_content)\n",
    "                news_id = news[\"id\"]\n",
    "                news_id_list.append(news_id)\n",
    "            f.close()\n",
    "    \n",
    "    return news_id_list, news_content_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(doc_set):\n",
    "    \n",
    "    '''\n",
    "    Args: a list of documents\n",
    "    Returns: a list of cleaned text\n",
    "    '''\n",
    "    \n",
    "    cleaned_texts = []\n",
    "    \n",
    "    for doc in doc_set:\n",
    "    \n",
    "        # clean and tokenize document string\n",
    "        raw_text = doc.lower()\n",
    "        raw_text = re.sub(r\"[^\\w\\s]\", \"\", raw_text)\n",
    "        tokens = nltk.word_tokenize(raw_text)\n",
    "\n",
    "        # remove stop words from tokens\n",
    "        stop = stopwords.words(\"english\")\n",
    "        cleaned_tokens = [token for token in tokens if token not in stop]\n",
    "\n",
    "        # add tokens to list\n",
    "        cleaned_texts.append(cleaned_tokens)\n",
    "        \n",
    "    return cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_lda(cleaned_texts, n_topics):\n",
    "    \n",
    "    '''\n",
    "    Args: a list of cleaned text\n",
    "    Returns: a lda model\n",
    "    '''\n",
    "    \n",
    "    dictionary = corpora.Dictionary(cleaned_texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in cleaned_texts]\n",
    "    \n",
    "    # need to tune parameter here\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=n_topics, id2word = dictionary, passes=10, \n",
    "                                               alpha = \"auto\", eta=\"auto\", eval_every=2)\n",
    "    \n",
    "    return ldamodel, corpus, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(ldamodel, corpus, news_id_list, n_topics):\n",
    "    \n",
    "    '''\n",
    "    Export LDA results to a file (topic collection and topic distributions of docs)\n",
    "    Args: lda model, corpus, the list of news IDs, number of topics\n",
    "    Returns: none\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1. get topic collections of documents\n",
    "    topic_dictionary = {} # initialize a dictionrary of <topicid, [docid, docid, ..]>\n",
    "    for i in range(0, n_topics):\n",
    "        topic_dictionary[i] = []\n",
    "    \n",
    "    for i in range(0,len(corpus)):\n",
    "        # get the topic with the highest probability\n",
    "        most_probable_topic = ldamodel[corpus[i]][0][0]\n",
    "        # add to the list\n",
    "        topic_dictionary[most_probable_topic].append(news_id_list[i])\n",
    "    \n",
    "    # save to a json file\n",
    "    with open(\"/Users/jiamingqu/Desktop/test.json\", 'w') as f:\n",
    "        json.dump(topic_dictionary,f)\n",
    "    f.close()\n",
    "    \n",
    "    # 2. get document distribution probability of topics\n",
    "    doc_prob_distribution = {}\n",
    "    for i in range(0,len(corpus)):\n",
    "        doc_prob_distribution[news_id_list[i]] = ldamodel[corpus[i]]\n",
    "    \n",
    "    # save to a json file\n",
    "    for k,v in doc_prob_distribution.items():\n",
    "        file_name = \"/Users/jiamingqu/Desktop/test2/\" + k + \".txt\"\n",
    "        with open(file_name, 'w') as f:\n",
    "            for item in v:\n",
    "                f.write(str(item))\n",
    "                f.write(\"\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    news_id_list, news_content_list = load_corpus(\"/Users/jiamingqu/Desktop/test/\")\n",
    "    cleaned_text = clean_text(news_content_list)\n",
    "    n_topics = 5\n",
    "    ldamodel, corpus, dictionary = training_lda(cleaned_text, n_topics)\n",
    "    save_results(ldamodel, corpus, news_id_list, n_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 11:49:05,209 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-03-24 11:49:05,221 : INFO : built Dictionary(4172 unique tokens: ['alaska', 'appreciate', 'asking', 'based', 'book']...) from 26 documents (total 10472 corpus positions)\n",
      "2020-03-24 11:49:05,283 : INFO : using autotuned alpha, starting with [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "2020-03-24 11:49:05,285 : INFO : using serial LDA version on this node\n",
      "2020-03-24 11:49:05,288 : INFO : running online (multi-pass) LDA training, 5 topics, 10 passes over the supplied corpus of 26 documents, updating model once every 26 documents, evaluating perplexity every 26 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2020-03-24 11:49:05,348 : INFO : -10.183 per-word bound, 1162.5 perplexity estimate based on a held-out corpus of 26 documents with 10472 words\n",
      "2020-03-24 11:49:05,349 : INFO : PROGRESS: pass 0, at document #26/26\n",
      "2020-03-24 11:49:05,379 : INFO : optimized alpha [0.35917443, 0.34348047, 0.3353486, 0.35493374, 0.33138976]\n",
      "2020-03-24 11:49:05,383 : INFO : topic #0 (0.359): 0.007*\"said\" + 0.004*\"would\" + 0.004*\"clinton\" + 0.003*\"trump\" + 0.003*\"new\" + 0.003*\"also\" + 0.003*\"police\" + 0.003*\"june\" + 0.003*\"one\" + 0.003*\"women\"\n",
      "2020-03-24 11:49:05,383 : INFO : topic #1 (0.343): 0.008*\"trump\" + 0.005*\"block\" + 0.005*\"june\" + 0.005*\"would\" + 0.005*\"said\" + 0.004*\"pm\" + 0.004*\"budget\" + 0.004*\"stolen\" + 0.004*\"new\" + 0.003*\"one\"\n",
      "2020-03-24 11:49:05,384 : INFO : topic #2 (0.335): 0.006*\"would\" + 0.005*\"trump\" + 0.005*\"said\" + 0.003*\"budget\" + 0.003*\"new\" + 0.003*\"also\" + 0.002*\"even\" + 0.002*\"one\" + 0.002*\"people\" + 0.002*\"police\"\n",
      "2020-03-24 11:49:05,385 : INFO : topic #3 (0.355): 0.006*\"government\" + 0.006*\"said\" + 0.005*\"speech\" + 0.005*\"would\" + 0.003*\"trump\" + 0.003*\"people\" + 0.003*\"money\" + 0.003*\"support\" + 0.003*\"first\" + 0.003*\"state\"\n",
      "2020-03-24 11:49:05,386 : INFO : topic #4 (0.331): 0.006*\"said\" + 0.006*\"would\" + 0.004*\"trump\" + 0.003*\"people\" + 0.003*\"government\" + 0.003*\"one\" + 0.003*\"police\" + 0.003*\"new\" + 0.002*\"hands\" + 0.002*\"protesters\"\n",
      "2020-03-24 11:49:05,386 : INFO : topic diff=1.492892, rho=1.000000\n",
      "2020-03-24 11:49:05,439 : INFO : -8.610 per-word bound, 390.6 perplexity estimate based on a held-out corpus of 26 documents with 10472 words\n",
      "2020-03-24 11:49:05,440 : INFO : PROGRESS: pass 1, at document #26/26\n",
      "2020-03-24 11:49:05,461 : INFO : optimized alpha [0.1585079, 0.062166244, 0.04274842, 0.08308497, 0.08356269]\n",
      "2020-03-24 11:49:05,464 : INFO : topic #0 (0.159): 0.007*\"said\" + 0.005*\"clinton\" + 0.004*\"women\" + 0.004*\"would\" + 0.004*\"also\" + 0.004*\"va\" + 0.004*\"new\" + 0.003*\"batman\" + 0.003*\"one\" + 0.003*\"sanders\"\n",
      "2020-03-24 11:49:05,465 : INFO : topic #1 (0.062): 0.012*\"trump\" + 0.010*\"june\" + 0.009*\"block\" + 0.007*\"stolen\" + 0.006*\"pm\" + 0.004*\"said\" + 0.004*\"would\" + 0.004*\"one\" + 0.004*\"media\" + 0.003*\"man\"\n",
      "2020-03-24 11:49:05,466 : INFO : topic #2 (0.043): 0.010*\"would\" + 0.008*\"budget\" + 0.006*\"trump\" + 0.006*\"said\" + 0.005*\"new\" + 0.004*\"programs\" + 0.004*\"also\" + 0.003*\"proposed\" + 0.003*\"funding\" + 0.003*\"billion\"\n",
      "2020-03-24 11:49:05,467 : INFO : topic #3 (0.083): 0.009*\"government\" + 0.006*\"speech\" + 0.005*\"money\" + 0.004*\"citizenship\" + 0.004*\"said\" + 0.004*\"people\" + 0.004*\"support\" + 0.003*\"political\" + 0.003*\"would\" + 0.003*\"ethnic\"\n",
      "2020-03-24 11:49:05,467 : INFO : topic #4 (0.084): 0.008*\"said\" + 0.005*\"hands\" + 0.004*\"would\" + 0.004*\"driving\" + 0.004*\"protesters\" + 0.004*\"careless\" + 0.004*\"police\" + 0.004*\"people\" + 0.003*\"court\" + 0.003*\"trooper\"\n",
      "2020-03-24 11:49:05,468 : INFO : topic diff=0.818020, rho=0.577350\n",
      "2020-03-24 11:49:05,513 : INFO : -8.078 per-word bound, 270.3 perplexity estimate based on a held-out corpus of 26 documents with 10472 words\n",
      "2020-03-24 11:49:05,513 : INFO : PROGRESS: pass 2, at document #26/26\n",
      "2020-03-24 11:49:05,530 : INFO : optimized alpha [0.09251186, 0.05072946, 0.039385483, 0.067574255, 0.06303955]\n",
      "2020-03-24 11:49:05,534 : INFO : topic #0 (0.093): 0.007*\"said\" + 0.006*\"clinton\" + 0.005*\"women\" + 0.004*\"va\" + 0.004*\"also\" + 0.004*\"would\" + 0.004*\"batman\" + 0.004*\"new\" + 0.004*\"black\" + 0.003*\"sanders\"\n",
      "2020-03-24 11:49:05,535 : INFO : topic #1 (0.051): 0.014*\"trump\" + 0.012*\"june\" + 0.011*\"block\" + 0.008*\"stolen\" + 0.007*\"pm\" + 0.004*\"media\" + 0.004*\"one\" + 0.004*\"man\" + 0.004*\"8\" + 0.004*\"said\"\n",
      "2020-03-24 11:49:05,536 : INFO : topic #2 (0.039): 0.012*\"would\" + 0.010*\"budget\" + 0.008*\"said\" + 0.008*\"trump\" + 0.005*\"new\" + 0.005*\"programs\" + 0.004*\"also\" + 0.004*\"proposed\" + 0.004*\"funding\" + 0.003*\"billion\"\n",
      "2020-03-24 11:49:05,537 : INFO : topic #3 (0.068): 0.009*\"government\" + 0.007*\"speech\" + 0.005*\"money\" + 0.005*\"citizenship\" + 0.004*\"people\" + 0.004*\"political\" + 0.004*\"support\" + 0.004*\"said\" + 0.004*\"ethnic\" + 0.003*\"pay\"\n",
      "2020-03-24 11:49:05,539 : INFO : topic #4 (0.063): 0.007*\"said\" + 0.006*\"hands\" + 0.005*\"driving\" + 0.005*\"protesters\" + 0.005*\"careless\" + 0.004*\"police\" + 0.004*\"trooper\" + 0.004*\"court\" + 0.004*\"appellant\" + 0.004*\"right\"\n",
      "2020-03-24 11:49:05,539 : INFO : topic diff=0.537559, rho=0.500000\n",
      "2020-03-24 11:49:05,588 : INFO : -7.943 per-word bound, 246.1 perplexity estimate based on a held-out corpus of 26 documents with 10472 words\n",
      "2020-03-24 11:49:05,589 : INFO : PROGRESS: pass 3, at document #26/26\n",
      "2020-03-24 11:49:05,601 : INFO : optimized alpha [0.068635836, 0.043569293, 0.036509696, 0.058150917, 0.050959423]\n",
      "2020-03-24 11:49:05,604 : INFO : topic #0 (0.069): 0.007*\"said\" + 0.006*\"clinton\" + 0.005*\"women\" + 0.005*\"va\" + 0.004*\"also\" + 0.004*\"batman\" + 0.004*\"black\" + 0.004*\"would\" + 0.004*\"new\" + 0.004*\"sanders\"\n",
      "2020-03-24 11:49:05,604 : INFO : topic #1 (0.044): 0.014*\"trump\" + 0.013*\"june\" + 0.012*\"block\" + 0.008*\"stolen\" + 0.007*\"pm\" + 0.005*\"media\" + 0.004*\"one\" + 0.004*\"man\" + 0.004*\"8\" + 0.004*\"primary\"\n",
      "2020-03-24 11:49:05,605 : INFO : topic #2 (0.037): 0.013*\"would\" + 0.010*\"budget\" + 0.009*\"said\" + 0.009*\"trump\" + 0.005*\"new\" + 0.005*\"programs\" + 0.004*\"also\" + 0.004*\"proposed\" + 0.004*\"funding\" + 0.003*\"police\"\n",
      "2020-03-24 11:49:05,606 : INFO : topic #3 (0.058): 0.009*\"government\" + 0.007*\"speech\" + 0.005*\"money\" + 0.005*\"citizenship\" + 0.004*\"people\" + 0.004*\"political\" + 0.004*\"support\" + 0.004*\"ethnic\" + 0.003*\"said\" + 0.003*\"pay\"\n",
      "2020-03-24 11:49:05,607 : INFO : topic #4 (0.051): 0.007*\"hands\" + 0.007*\"said\" + 0.006*\"driving\" + 0.005*\"protesters\" + 0.005*\"careless\" + 0.005*\"police\" + 0.004*\"trooper\" + 0.004*\"appellant\" + 0.004*\"court\" + 0.004*\"right\"\n",
      "2020-03-24 11:49:05,608 : INFO : topic diff=0.332885, rho=0.447214\n",
      "2020-03-24 11:49:05,650 : INFO : -7.917 per-word bound, 241.7 perplexity estimate based on a held-out corpus of 26 documents with 10472 words\n",
      "2020-03-24 11:49:05,651 : INFO : PROGRESS: pass 4, at document #26/26\n",
      "2020-03-24 11:49:05,662 : INFO : optimized alpha [0.057091698, 0.038656253, 0.034132294, 0.051826734, 0.04371077]\n",
      "2020-03-24 11:49:05,665 : INFO : topic #0 (0.057): 0.007*\"said\" + 0.006*\"clinton\" + 0.006*\"women\" + 0.005*\"va\" + 0.005*\"batman\" + 0.005*\"also\" + 0.005*\"black\" + 0.004*\"would\" + 0.004*\"sanders\" + 0.004*\"new\"\n",
      "2020-03-24 11:49:05,666 : INFO : topic #1 (0.039): 0.015*\"trump\" + 0.013*\"june\" + 0.012*\"block\" + 0.009*\"stolen\" + 0.008*\"pm\" + 0.005*\"media\" + 0.004*\"one\" + 0.004*\"man\" + 0.004*\"8\" + 0.004*\"primary\"\n",
      "2020-03-24 11:49:05,667 : INFO : topic #2 (0.034): 0.014*\"would\" + 0.010*\"budget\" + 0.010*\"said\" + 0.009*\"trump\" + 0.006*\"new\" + 0.006*\"programs\" + 0.004*\"also\" + 0.004*\"proposed\" + 0.004*\"funding\" + 0.003*\"police\"\n",
      "2020-03-24 11:49:05,668 : INFO : topic #3 (0.052): 0.009*\"government\" + 0.007*\"speech\" + 0.005*\"money\" + 0.005*\"citizenship\" + 0.004*\"people\" + 0.004*\"political\" + 0.004*\"support\" + 0.004*\"ethnic\" + 0.003*\"pay\" + 0.003*\"said\"\n",
      "2020-03-24 11:49:05,669 : INFO : topic #4 (0.044): 0.007*\"hands\" + 0.006*\"driving\" + 0.006*\"said\" + 0.006*\"protesters\" + 0.006*\"careless\" + 0.005*\"police\" + 0.005*\"trooper\" + 0.005*\"appellant\" + 0.004*\"court\" + 0.004*\"right\"\n",
      "2020-03-24 11:49:05,670 : INFO : topic diff=0.209394, rho=0.408248\n",
      "2020-03-24 11:49:05,715 : INFO : -7.916 per-word bound, 241.6 perplexity estimate based on a held-out corpus of 26 documents with 10472 words\n",
      "2020-03-24 11:49:05,716 : INFO : PROGRESS: pass 5, at document #26/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 11:49:05,727 : INFO : optimized alpha [0.049883414, 0.035024986, 0.032138966, 0.04721444, 0.038752023]\n",
      "2020-03-24 11:49:05,731 : INFO : topic #0 (0.050): 0.007*\"said\" + 0.006*\"women\" + 0.006*\"clinton\" + 0.005*\"va\" + 0.005*\"black\" + 0.005*\"batman\" + 0.005*\"also\" + 0.004*\"would\" + 0.004*\"sanders\" + 0.004*\"new\"\n",
      "2020-03-24 11:49:05,731 : INFO : topic #1 (0.035): 0.015*\"trump\" + 0.013*\"june\" + 0.012*\"block\" + 0.009*\"stolen\" + 0.008*\"pm\" + 0.005*\"media\" + 0.005*\"one\" + 0.005*\"man\" + 0.005*\"8\" + 0.004*\"primary\"\n",
      "2020-03-24 11:49:05,732 : INFO : topic #2 (0.032): 0.014*\"would\" + 0.011*\"budget\" + 0.010*\"said\" + 0.009*\"trump\" + 0.006*\"new\" + 0.006*\"programs\" + 0.004*\"also\" + 0.004*\"proposed\" + 0.004*\"funding\" + 0.004*\"police\"\n",
      "2020-03-24 11:49:05,733 : INFO : topic #3 (0.047): 0.009*\"government\" + 0.007*\"speech\" + 0.005*\"money\" + 0.005*\"citizenship\" + 0.004*\"people\" + 0.004*\"political\" + 0.004*\"support\" + 0.004*\"ethnic\" + 0.004*\"pay\" + 0.003*\"said\"\n",
      "2020-03-24 11:49:05,733 : INFO : topic #4 (0.039): 0.007*\"hands\" + 0.007*\"driving\" + 0.006*\"said\" + 0.006*\"protesters\" + 0.006*\"careless\" + 0.005*\"police\" + 0.005*\"trooper\" + 0.005*\"appellant\" + 0.004*\"court\" + 0.004*\"right\"\n",
      "2020-03-24 11:49:05,734 : INFO : topic diff=0.136623, rho=0.377964\n",
      "2020-03-24 11:49:05,777 : INFO : -7.918 per-word bound, 241.9 perplexity estimate based on a held-out corpus of 26 documents with 10472 words\n",
      "2020-03-24 11:49:05,778 : INFO : PROGRESS: pass 6, at document #26/26\n",
      "2020-03-24 11:49:05,791 : INFO : optimized alpha [0.04483987, 0.03219724, 0.030441979, 0.043662816, 0.035094608]\n",
      "2020-03-24 11:49:05,794 : INFO : topic #0 (0.045): 0.007*\"said\" + 0.006*\"women\" + 0.006*\"clinton\" + 0.005*\"va\" + 0.005*\"black\" + 0.005*\"batman\" + 0.005*\"also\" + 0.004*\"would\" + 0.004*\"kids\" + 0.004*\"sanders\"\n",
      "2020-03-24 11:49:05,795 : INFO : topic #1 (0.032): 0.016*\"trump\" + 0.014*\"june\" + 0.013*\"block\" + 0.009*\"stolen\" + 0.008*\"pm\" + 0.005*\"media\" + 0.005*\"one\" + 0.005*\"man\" + 0.005*\"8\" + 0.004*\"primary\"\n",
      "2020-03-24 11:49:05,796 : INFO : topic #2 (0.030): 0.014*\"would\" + 0.011*\"budget\" + 0.010*\"said\" + 0.010*\"trump\" + 0.006*\"new\" + 0.006*\"programs\" + 0.004*\"also\" + 0.004*\"proposed\" + 0.004*\"funding\" + 0.004*\"police\"\n",
      "2020-03-24 11:49:05,797 : INFO : topic #3 (0.044): 0.009*\"government\" + 0.007*\"speech\" + 0.005*\"money\" + 0.005*\"citizenship\" + 0.004*\"people\" + 0.004*\"political\" + 0.004*\"support\" + 0.004*\"ethnic\" + 0.004*\"pay\" + 0.003*\"said\"\n",
      "2020-03-24 11:49:05,798 : INFO : topic #4 (0.035): 0.008*\"hands\" + 0.007*\"driving\" + 0.006*\"protesters\" + 0.006*\"careless\" + 0.006*\"said\" + 0.005*\"police\" + 0.005*\"trooper\" + 0.005*\"appellant\" + 0.004*\"court\" + 0.004*\"right\"\n",
      "2020-03-24 11:49:05,799 : INFO : topic diff=0.093483, rho=0.353553\n",
      "2020-03-24 11:49:05,842 : INFO : -7.916 per-word bound, 241.5 perplexity estimate based on a held-out corpus of 26 documents with 10472 words\n",
      "2020-03-24 11:49:05,843 : INFO : PROGRESS: pass 7, at document #26/26\n",
      "2020-03-24 11:49:05,855 : INFO : optimized alpha [0.041059356, 0.029904103, 0.02897665, 0.04081999, 0.032258987]\n",
      "2020-03-24 11:49:05,858 : INFO : topic #0 (0.041): 0.007*\"said\" + 0.006*\"women\" + 0.005*\"clinton\" + 0.005*\"va\" + 0.005*\"black\" + 0.005*\"batman\" + 0.005*\"also\" + 0.004*\"kids\" + 0.004*\"would\" + 0.004*\"food\"\n",
      "2020-03-24 11:49:05,859 : INFO : topic #1 (0.030): 0.016*\"trump\" + 0.014*\"june\" + 0.013*\"block\" + 0.009*\"stolen\" + 0.008*\"pm\" + 0.006*\"media\" + 0.005*\"one\" + 0.005*\"man\" + 0.005*\"8\" + 0.004*\"primary\"\n",
      "2020-03-24 11:49:05,860 : INFO : topic #2 (0.029): 0.014*\"would\" + 0.011*\"budget\" + 0.011*\"said\" + 0.010*\"trump\" + 0.006*\"new\" + 0.006*\"programs\" + 0.004*\"also\" + 0.004*\"proposed\" + 0.004*\"funding\" + 0.004*\"police\"\n",
      "2020-03-24 11:49:05,861 : INFO : topic #3 (0.041): 0.009*\"government\" + 0.007*\"speech\" + 0.005*\"money\" + 0.005*\"citizenship\" + 0.004*\"people\" + 0.004*\"political\" + 0.004*\"support\" + 0.004*\"ethnic\" + 0.004*\"pay\" + 0.003*\"said\"\n",
      "2020-03-24 11:49:05,861 : INFO : topic #4 (0.032): 0.008*\"hands\" + 0.007*\"driving\" + 0.006*\"protesters\" + 0.006*\"careless\" + 0.006*\"said\" + 0.005*\"police\" + 0.005*\"trooper\" + 0.005*\"appellant\" + 0.004*\"court\" + 0.004*\"right\"\n",
      "2020-03-24 11:49:05,862 : INFO : topic diff=0.065803, rho=0.333333\n",
      "2020-03-24 11:49:05,903 : INFO : -7.912 per-word bound, 240.9 perplexity estimate based on a held-out corpus of 26 documents with 10472 words\n",
      "2020-03-24 11:49:05,903 : INFO : PROGRESS: pass 8, at document #26/26\n",
      "2020-03-24 11:49:05,914 : INFO : optimized alpha [0.03806372, 0.027608901, 0.02768207, 0.038450997, 0.029963875]\n",
      "2020-03-24 11:49:05,917 : INFO : topic #0 (0.038): 0.007*\"said\" + 0.006*\"women\" + 0.005*\"clinton\" + 0.005*\"va\" + 0.005*\"black\" + 0.005*\"batman\" + 0.005*\"also\" + 0.004*\"food\" + 0.004*\"kids\" + 0.004*\"would\"\n",
      "2020-03-24 11:49:05,918 : INFO : topic #1 (0.028): 0.016*\"trump\" + 0.014*\"june\" + 0.013*\"block\" + 0.010*\"stolen\" + 0.008*\"pm\" + 0.006*\"media\" + 0.005*\"one\" + 0.005*\"man\" + 0.005*\"8\" + 0.004*\"primary\"\n",
      "2020-03-24 11:49:05,919 : INFO : topic #2 (0.028): 0.014*\"would\" + 0.011*\"budget\" + 0.011*\"said\" + 0.010*\"trump\" + 0.006*\"new\" + 0.006*\"programs\" + 0.004*\"also\" + 0.004*\"proposed\" + 0.004*\"funding\" + 0.004*\"police\"\n",
      "2020-03-24 11:49:05,919 : INFO : topic #3 (0.038): 0.009*\"government\" + 0.007*\"speech\" + 0.005*\"money\" + 0.005*\"citizenship\" + 0.004*\"people\" + 0.004*\"political\" + 0.004*\"support\" + 0.004*\"ethnic\" + 0.004*\"pay\" + 0.003*\"said\"\n",
      "2020-03-24 11:49:05,920 : INFO : topic #4 (0.030): 0.008*\"hands\" + 0.007*\"driving\" + 0.006*\"protesters\" + 0.006*\"careless\" + 0.006*\"said\" + 0.005*\"police\" + 0.005*\"trooper\" + 0.005*\"appellant\" + 0.005*\"court\" + 0.004*\"right\"\n",
      "2020-03-24 11:49:05,921 : INFO : topic diff=0.045833, rho=0.316228\n",
      "2020-03-24 11:49:05,961 : INFO : -7.911 per-word bound, 240.7 perplexity estimate based on a held-out corpus of 26 documents with 10472 words\n",
      "2020-03-24 11:49:05,962 : INFO : PROGRESS: pass 9, at document #26/26\n",
      "2020-03-24 11:49:05,972 : INFO : optimized alpha [0.03563036, 0.025726793, 0.026536569, 0.036452845, 0.028068248]\n",
      "2020-03-24 11:49:05,974 : INFO : topic #0 (0.036): 0.007*\"said\" + 0.006*\"women\" + 0.005*\"clinton\" + 0.005*\"va\" + 0.005*\"black\" + 0.005*\"batman\" + 0.005*\"also\" + 0.005*\"food\" + 0.004*\"kids\" + 0.004*\"would\"\n",
      "2020-03-24 11:49:05,975 : INFO : topic #1 (0.026): 0.016*\"trump\" + 0.015*\"june\" + 0.013*\"block\" + 0.010*\"stolen\" + 0.008*\"pm\" + 0.006*\"media\" + 0.005*\"one\" + 0.005*\"man\" + 0.005*\"8\" + 0.004*\"primary\"\n",
      "2020-03-24 11:49:05,976 : INFO : topic #2 (0.027): 0.014*\"would\" + 0.011*\"budget\" + 0.011*\"said\" + 0.010*\"trump\" + 0.006*\"new\" + 0.006*\"programs\" + 0.004*\"also\" + 0.004*\"proposed\" + 0.004*\"funding\" + 0.004*\"police\"\n",
      "2020-03-24 11:49:05,977 : INFO : topic #3 (0.036): 0.009*\"government\" + 0.007*\"speech\" + 0.005*\"money\" + 0.005*\"citizenship\" + 0.004*\"people\" + 0.004*\"political\" + 0.004*\"support\" + 0.004*\"ethnic\" + 0.004*\"pay\" + 0.003*\"said\"\n",
      "2020-03-24 11:49:05,977 : INFO : topic #4 (0.028): 0.008*\"hands\" + 0.007*\"driving\" + 0.006*\"protesters\" + 0.006*\"careless\" + 0.006*\"said\" + 0.005*\"police\" + 0.005*\"trooper\" + 0.005*\"appellant\" + 0.005*\"court\" + 0.004*\"right\"\n",
      "2020-03-24 11:49:05,978 : INFO : topic diff=0.032245, rho=0.301511\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
